#DÃ©tection de Fraudes Bancaires (Pipeline MLOps)

**Contexte**
Les fraudes bancaires coÃ»tent des milliards chaque annÃ©e. Lâ€™objectif de ce projet est de dÃ©tecter automatiquement les transactions frauduleuses dans un dataset rÃ©el de transactions bancaires synthÃ©tiques, tout en proposant une solution industrialisÃ©e via un pipeline MLOps.

ğŸ“Š**Dataset**
 Le dataset utilisÃ© provient de Kaggle : https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud
 Format CSV, 284807 transactions
 30 features (V1-V28, Time, Amount)
 Classe cible Class :
 0 â†’ Transaction normale
 1 â†’ Transaction frauduleuse (~0.17% des transactions)

ğŸ¯**Objectifs**
 1-Analyser les transactions et dÃ©tecter les patterns suspects
 2-Construire un modÃ¨le de classification robuste (Random Forest, XGBoost)
 3-GÃ©rer le dÃ©sÃ©quilibre extrÃªme des classes (SMOTE)
 4-DÃ©ployer une API pour prÃ©dire les fraudes en temps rÃ©el
 5-IntÃ©grer un systÃ¨me de logs pour le suivi des prÃ©dictions

  ğŸ› ï¸**MÃ©thodologie**
  1.Analyse exploratoire (EDA)
   Visualisation de la distribution des classes
   Ã‰tude des correlations et des patterns des features

  2. PrÃ©traitement
   SÃ©paration des features (X) et de la cible (y)
   Split train/test stratifiÃ© (70% / 30%)
   Gestion des variables catÃ©gorielles avec pd.get_dummies()
   RÃ©Ã©chantillonnage de la classe minoritaire via SMOTE

  3. ModÃ©lisation
    *Random Forest*
    Pipeline avec StandardScaler et RandomForestClassifier
    Poids Ã©quilibrÃ©s pour la classe minoritaire
    *XGBoost* (modÃ¨le final)
    Pipeline avec StandardScaler et XGBClassifier
    HyperparamÃ¨tres : n_estimators=100, eval_metric='logloss'

  4. Ã‰valuation
    MÃ©triques principales :
    Recall sur la classe fraude (minimiser les fausses nÃ©gatives)
    AUC-ROC pour la performance globale

Comparaison des modÃ¨les :
| ModÃ¨le                | Recall (Fraude) | AUC-ROC Score |
| --------------------- | --------------- | ------------- |
| Random Forest         | 0.7905          | 0.9494        |
| XGBoost (sÃ©lectionnÃ©) | **0.7973**      | **0.9779**    |


ğŸš€**DÃ©ploiement et MLOps**
Architecture
 1-Le modÃ¨le XGBoost entraÃ®nÃ© est sÃ©rialisÃ© en xgb_fraud_detector.joblib
 2-La liste des features est sauvegardÃ©e dans features.pkl
 3-Une API FastAPI est crÃ©Ã©e (api/main.py)
   .SchÃ©ma dâ€™entrÃ©e validÃ© avec Pydantic
   .PrÃ©diction en temps rÃ©el sur les 30 features
 4-Logging MLOps :
   .Chaque requÃªte, la prÃ©diction et le temps de rÃ©ponse sont enregistrÃ©s dans api_predictions.log
   .PrÃ©paration pour le suivi de la dÃ©rive des donnÃ©es (concept drift)
   
Lancer lâ€™API
PrÃ©requis : Docker Desktop installÃ© et lancÃ©
# Construire l'image Docker
docker build -t fraude-api .

# Lancer le conteneur
docker run -d --name Detection_Fraude -p 8000:8000 fraude-api

# Tester l'API via Swagger
http://localhost:8000/docs


ğŸ“‚Structure du projet

Projet_Fraude/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py                 # Code FastAPI + Logging
â”œâ”€â”€ model_artefacts/
â”‚   â”œâ”€â”€ xgb_fraud_detector.joblib
â”‚   â””â”€â”€ features.pkl
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Detection_de_Fraude.ipynb      # Notebook complet (EDA, ModÃ©lisation)
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt


âœ…**Conclusion**
XGBoost est le modÃ¨le retenu pour sa performance sur les fraudes (Recall et AUC-ROC Ã©levÃ©s)
Le projet est industrialisation-ready grÃ¢ce Ã  Docker et FastAPI
Les logs assurent une traÃ§abilitÃ© des prÃ©dictions, base pour un futur suivi de dÃ©rive
